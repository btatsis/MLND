{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem.EState import Fingerprinter\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem.rdmolops import RDKFingerprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import cross_validation\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from sklearn import cross_validation\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#from rdkit.Avalon.pyAvalonTools import GetAvalonFP\n",
    "#from rdkit.Avalon import pyAvalonTools\n",
    "\n",
    "\n",
    "#Read solubility data\n",
    "training_data = pd.read_csv('train_huuskonsen.csv')\n",
    "print(training_data.head())\n",
    "\n",
    "def estate_fingerprint_and_mw(mol):\n",
    "    return np.append(FingerprintMol(mol)[0], Descriptors.MolWt(x))\n",
    "\n",
    "#Add some new columns\n",
    "training_data['Mol'] = training_data['smiles'].apply(Chem.MolFromSmiles)\n",
    "num_mols = len(training_data)\n",
    "\n",
    "#Create X and y\n",
    "#Convert to Numpy arrays\n",
    "y = training_data['solubility'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we make a bunch of different fingerprints. \n",
    "To do this, I have created a fingerprint object, which stores the name of the fingerprint and contains a method for applying the fingerprint and then converting the output into a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from rdkit.Chem.rdMolDescriptors import GetMorganFingerprint, GetHashedAtomPairFingerprintAsBitVect\n",
    "from rdkit.Chem.rdMolDescriptors import GetHashedTopologicalTorsionFingerprintAsBitVect\n",
    "from rdkit.Chem.AtomPairs.Sheridan import GetBPFingerprint\n",
    "from rdkit.Chem.EState.Fingerprinter import FingerprintMol\n",
    "#from rdkit.Avalon.pyAvalonTools import GetAvalonFP #GetAvalonCountFP  #int vector version\n",
    "from rdkit.Chem.AllChem import  GetMorganFingerprintAsBitVect, GetErGFingerprint\n",
    "from rdkit.DataStructs.cDataStructs import ConvertToNumpyArray\n",
    "import rdkit.DataStructs.cDataStructs\n",
    "\n",
    "def ExplicitBitVect_to_NumpyArray(bitvector):\n",
    "    bitstring = bitvector.ToBitString()\n",
    "    intmap = map(int, bitstring)\n",
    "    return np.array(list(intmap))\n",
    "\n",
    "class fingerprint():\n",
    "    def __init__(self, fp_fun, name):\n",
    "        self.fp_fun = fp_fun\n",
    "        self.name = name\n",
    "        self.x = []\n",
    "\n",
    "    def apply_fp(self, mols):\n",
    "        for mol in mols:\n",
    "            fp = self.fp_fun(mol)\n",
    "            if isinstance(fp, tuple):\n",
    "                fp = np.array(list(fp[0]))\n",
    "            if isinstance(fp, rdkit.DataStructs.cDataStructs.ExplicitBitVect):\n",
    "                fp = ExplicitBitVect_to_NumpyArray(fp)\n",
    "            if isinstance(fp,rdkit.DataStructs.cDataStructs.IntSparseIntVect):\n",
    "                fp = np.array(list(fp))\n",
    "\n",
    "            self.x += [fp]\n",
    "\n",
    "            if (str(type(self.x[0])) != \"<class 'numpy.ndarray'>\"):\n",
    "                print(\"WARNING: type for \", self.name, \"is \", type(self.x[0]))\n",
    "\n",
    "def make_fingerprints(length = 512, verbose=False):\n",
    "    fp_list = [\n",
    "         #fingerprint(lambda x : GetBPFingerprint(x, fpfn=AtomPair), \n",
    "         #            \"Physiochemical properties (1996)\"), ##NOTE: takes a long time to compute\n",
    "         fingerprint(lambda x : GetHashedAtomPairFingerprintAsBitVect(x, nBits = length),\n",
    "                     \"Atom pair (1985)\"),\n",
    "         fingerprint(lambda x : GetHashedTopologicalTorsionFingerprintAsBitVect(x, nBits = length),\n",
    "                     \"Topological torsion (1987)\"),\n",
    "         fingerprint(lambda x : GetMorganFingerprintAsBitVect(x, 2, nBits = length),\n",
    "                     \"Morgan circular \"),\n",
    "         fingerprint(FingerprintMol, \"Estate (1995)\"),\n",
    "        # fingerprint(lambda x: GetAvalonFP(x, nBits=length),\n",
    "        #            \"Avalon bit based (2006)\"),\n",
    "        # fingerprint(lambda x: np.append(GetAvalonFP(x, nBits=length), Descriptors.MolWt(x)),\n",
    "        #            \"Avalon+mol. weight\"),\n",
    "         fingerprint(lambda x: GetErGFingerprint(x), \"ErG fingerprint (2006)\"),\n",
    "         fingerprint(lambda x : RDKFingerprint(x, fpSize=length),\n",
    "                     \"RDKit fingerprint\")\n",
    "    ]\n",
    "\n",
    "    for fp in fp_list:\n",
    "        if (verbose): print(\"doing\", fp.name)\n",
    "        fp.apply_fp(list(training_data['Mol']))\n",
    "\n",
    "    return fp_list\n",
    "\n",
    "fp_list = make_fingerprints()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_cv(model, x, y, cv=20):\n",
    "    scores = cross_validation.cross_val_score(model, x, y, cv=cv, n_jobs=-1, \n",
    "    scoring='neg_mean_absolute_error')\n",
    "\n",
    "    scores = -1*scores\n",
    "\n",
    "    return scores.mean()\n",
    "\n",
    "\n",
    "def test_fingerprints(fp_list, model, y, verbose = True):\n",
    "\n",
    "    fingerprint_scores = {}\n",
    "\n",
    "    for fp in fp_list:\n",
    "        if verbose: print(\"doing \", fp.name)\n",
    "        fingerprint_scores[fp.name] = test_model_cv(model, fp.x, y)\n",
    "\n",
    "    sorted_names = sorted(fingerprint_scores, key=fingerprint_scores.__getitem__, reverse=False)\n",
    "\n",
    "    print(\"\\\\begin{tabular}{c c}\")\n",
    "    print(\"           name        &  avg abs error in CV (kJ/cc) \\\\\\\\\")\n",
    "    print(\"\\\\hline\")\n",
    "    for i in range(len(sorted_names)):\n",
    "        name = sorted_names[i]\n",
    "        print(\"%30s & %5.3f \\\\\\\\\" % (name, fingerprint_scores[name]))\n",
    "    print(\"\\\\end{tabular}\")\n",
    "\n",
    "\n",
    "test_fingerprints(fp_list, Ridge(alpha=1e-9), y, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estate_fingerprint(mol):\n",
    "    return FingerprintMol(mol)[0]\n",
    "\n",
    "#Scale X to unit variance and zero mean\n",
    "training_data['Fingerprint'] = training_data['Mol'].apply(estate_fingerprint)\n",
    "\n",
    "X = np.array(list(training_data['Fingerprint']))\n",
    "\n",
    "st = StandardScaler()\n",
    "X = np.array(list(training_data['Fingerprint']))\n",
    "X = st.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KRmodel = GridSearchCV(KernelRidge(), cv=10,\n",
    "              param_grid={\"alpha\": np.logspace(-10, -5, 10),\n",
    "             \"gamma\": np.logspace(-12, -9, 10), \"kernel\" : ['laplacian', 'rbf']}, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "\n",
    "KRmodel = KRmodel.fit(X, y)\n",
    "Best_KernelRidge = KRmodel.best_estimator_\n",
    "print(\"Best Kernel Ridge model\")\n",
    "print(KRmodel.best_params_)\n",
    "print(-1*KRmodel.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rmodel = GridSearchCV(Ridge(), cv=20,\n",
    "              param_grid={\"alpha\": np.logspace(-10, -5, 30),}, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "\n",
    "Rmodel = Rmodel.fit(X, y)\n",
    "Best_Ridge = Rmodel.best_estimator_\n",
    "print(\"Best Ridge model\")\n",
    "print(Rmodel.best_params_)\n",
    "print(-1*Rmodel.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPmodel = GridSearchCV(GaussianProcessRegressor(normalize_y=True), cv=20,\n",
    "              param_grid={\"alpha\": np.logspace(-15, -10, 30),}, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "GPmodel = GPmodel.fit(X, y)\n",
    "Best_GaussianProcessRegressor = GPmodel.best_estimator_\n",
    "print(\"Best Gaussian Process model\")\n",
    "print(GPmodel.best_params_)\n",
    "print(-1*GPmodel.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFmodel = GridSearchCV(RandomForestRegressor(), cv=20,\n",
    "              param_grid={\"n_estimators\": np.linspace(50, 150, 25).astype('int')}, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "\n",
    "RFmodel = RFmodel.fit(X, y)\n",
    "Best_RandomForestRegressor = RFmodel.best_estimator_\n",
    "print(\"Best Random Forest model\")\n",
    "print(RFmodel.best_params_)\n",
    "print(-1*RFmodel.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "\n",
    "def make_scatter_plot(y_pred_train, y_pred_test, y_train, y_test, title='', figsize=(6,4), fontsize=16):    \n",
    "    plt.clf()\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.scatter(y_train,y_pred_train, label = 'Train', c='blue')\n",
    "    plt.title(title,fontsize=fontsize+5)\n",
    "    plt.xlabel('Experimental Solubility (mol/L)', fontsize=fontsize)\n",
    "    plt.ylabel('Predicted Solubility (mol/L)', fontsize=fontsize)\n",
    "    plt.scatter(y_test,y_pred_test,c='lightgreen', label='Test', alpha = 0.8)\n",
    "    plt.legend(loc=4)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def test_models_and_plot(x, y, model_dict, plots=True):\n",
    "    ''' test a bunch of models and print out a sorted list of CV accuracies\n",
    "        inputs: \n",
    "            x: training data features, numpy array or Pandas dataframe\n",
    "            y: training data labels, numpy array or Pandas dataframe\n",
    "            model_dict: a dictionary of the form {name : model()}, where 'name' is a string\n",
    "                        and 'model()' is a sci-kit-learn model object. \n",
    "    '''\n",
    "\n",
    "    mean_scores = {}\n",
    "    percent_errors = {}\n",
    "\n",
    "    for (name, model) in model_dict.items():\n",
    "        #print(\"running %s\" % name)\n",
    "        scores = cross_validation.cross_val_score(model, x, y, cv=20, n_jobs=-1, scoring='neg_mean_absolute_error')\n",
    "        scores = -1*scores\n",
    "        mean_score = scores.mean()\n",
    "        mean_scores[name] = mean_score\n",
    "\n",
    "        X_train, X_test, y_train, y_test = cross_validation.train_test_split(x, y, test_size=0.1)\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # save RF model in pickle object\n",
    "        if name == 'Random forest':\n",
    "            f = open('rf_model.pkl', 'wb')\n",
    "            pickle.dump(model, f)\n",
    "            f.close()\n",
    "            \n",
    "        y_pred_train = model.predict(X_train)\n",
    "\n",
    "        y_pred_test  = model.predict(X_test)\n",
    "\n",
    "        percent_error = np.mean( 100*np.abs(y_test -y_pred_test)/np.abs(y_pred_test))\n",
    "\n",
    "        percent_errors[name] = percent_error\n",
    "\n",
    "        fulltitle = name+'\\n mean % error: '+str(percent_error)\n",
    "\n",
    "        if plots:\n",
    "            make_scatter_plot(y_pred_train, y_pred_test, y_train, y_test, title=fulltitle, figsize = (8,6))\n",
    "\n",
    "    sorted_names = sorted(percent_errors, key=mean_scores.__getitem__, reverse=False)\n",
    "\n",
    "    print(\"\\\\begin{tabular}{c c c}\")\n",
    "    print(\"           name     &      % test err   & .    abs error in CV \\\\\\\\ \")\n",
    "    print(\"\\\\hline\")\n",
    "    for i in range(len(sorted_names)):\n",
    "        name = sorted_names[i]\n",
    "        print(\"%30s & %5.3f & %5.3f \\\\\\\\\" % (name, percent_errors[name], mean_scores[name]))\n",
    "    print(\"\\\\end{tabular}\")\n",
    "\n",
    "\n",
    "alpha_grid = {'alpha': np.logspace(1e-11,1e-1,8)}\n",
    "\n",
    "model_dict = {\n",
    "            'Linear Regression': LinearRegression(),\n",
    "            #'Kernel Ridge Regression': Best_KernelRidge,\n",
    "            #'Ridge Regression':Best_Ridge,\n",
    "            #'Guassian Process Regressor': Best_GaussianProcessRegressor,\n",
    "            'Support Vector Regression': SVR(),\n",
    "            'KNeighborsRegressor': KNeighborsRegressor(),\n",
    "            #'Neural Network': MLPRegressor(alpha=100,max_iter=8000, hidden_layer_sizes=[8,6], early_stopping=False),\n",
    "            'Gradient Boosted Trees': GradientBoostingRegressor(n_estimators=100),\n",
    "            'Random forest': Best_RandomForestRegressor\n",
    "            }\n",
    "\n",
    "test_models_and_plot(X, y, model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
