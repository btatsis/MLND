{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/btatsis/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/btatsis/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# RDKit packages\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import PandasTools\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem import Descriptors\n",
    "\n",
    "\n",
    "# RDKit descriptors\n",
    "from rdkit.Chem.EState import Fingerprinter\n",
    "from rdkit.Chem.rdmolops import RDKFingerprint\n",
    "from rdkit.Avalon.pyAvalonTools import GetAvalonFP\n",
    "from rdkit.Avalon import pyAvalonTools\n",
    "from rdkit.Chem.rdMolDescriptors import GetMorganFingerprint, GetHashedAtomPairFingerprintAsBitVect\n",
    "from rdkit.Chem.rdMolDescriptors import GetHashedTopologicalTorsionFingerprintAsBitVect\n",
    "from rdkit.Chem.AtomPairs.Sheridan import GetBPFingerprint\n",
    "from rdkit.Chem.EState.Fingerprinter import FingerprintMol\n",
    "from rdkit.Avalon.pyAvalonTools import GetAvalonFP \n",
    "from rdkit.Chem.AllChem import  GetMorganFingerprintAsBitVect, GetErGFingerprint\n",
    "from rdkit.DataStructs.cDataStructs import ConvertToNumpyArray\n",
    "import rdkit.DataStructs.cDataStructs\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.linear_model import Ridge, BayesianRidge, LinearRegression\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import cross_validation\n",
    "\n",
    "#from xgboost import XGBClassifier\n",
    "#import lightgbm as lgbm\n",
    "\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 smiles  solubility  logp\n",
      "0  c1ccccc1c2cc(Cl)ccc2       -4.88  4.40\n",
      "1  O=N(=O)c(c(ccc1)C)c1       -2.33  2.36\n",
      "2          CC(O)CCC(C)C       -1.38  2.17\n",
      "The Huuskonsen data set contains  1297  compounds\n"
     ]
    }
   ],
   "source": [
    "#Read solubility data\n",
    "sol_data = pd.read_csv('datasets/huuskonsen_data.csv')\n",
    "print(sol_data.head(n=3))\n",
    "\n",
    "def estate_fingerprint_and_mw(mol):\n",
    "    return np.append(FingerprintMol(mol)[0], Descriptors.MolWt(x))\n",
    "\n",
    "#Add some new columns\n",
    "sol_data['ROMol'] = sol_data['smiles'].apply(Chem.MolFromSmiles)\n",
    "print(\"The Huuskonsen data set contains \", len(sol_data), \" compounds\")\n",
    "\n",
    "# Adding a few more descriptors (MW, HAC, RingCount, and TPSA)\n",
    "# Althought, in this project we will use only the structural fingerprints \n",
    "# to calculate a small molecule's logp\n",
    "sol_data['MW']             = sol_data['ROMol'].map(Descriptors.MolWt)\n",
    "sol_data['HeavyAtomCount'] = sol_data['ROMol'].map(Descriptors.HeavyAtomCount)\n",
    "sol_data['RingCount']      = sol_data['ROMol'].map(Descriptors.RingCount)\n",
    "sol_data['TPSA']           = sol_data['ROMol'].map(Descriptors.TPSA)\n",
    "\n",
    "# Add Chemical structure to Pandas frame\n",
    "PandasTools.AddMoleculeColumnToFrame(sol_data,smilesCol='smiles',molCol='ROMol',includeFingerprints=True)\n",
    "\n",
    "# Target values\n",
    "y = sol_data['solubility'].values\n",
    "#sol_data.head(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting Estate fingerprints\n",
      "Converting Morgan fingerprints\n",
      "Converting RDKit fingerprints\n",
      "Converting Topological torsion fingerprints\n",
      "Converting Extended reduced graph approach fingerprints\n",
      "Converting Avalon bit based fingerprints\n"
     ]
    }
   ],
   "source": [
    "print(\"Converting Estate fingerprints\")\n",
    "\n",
    "# Estate fingerprints\n",
    "def estate_fingerprint(mol):\n",
    "    return FingerprintMol(mol)[0]\n",
    "\n",
    "sol_data['fp_Estate'] = sol_data['ROMol'].apply(estate_fingerprint)\n",
    "\n",
    "print(\"Converting Morgan fingerprints\")\n",
    "\n",
    "# Morgan fingerprints, length 1024 bits\n",
    "def Morgan_fingerprint(mol):\n",
    "    fp = np.zeros((1,))\n",
    "    ConvertToNumpyArray(GetMorganFingerprintAsBitVect(mol, 2, nBits = 1024), fp)\n",
    "    return fp\n",
    "\n",
    "sol_data['fp_Morgan'] = sol_data['ROMol'].apply(Morgan_fingerprint)\n",
    "\n",
    "print(\"Converting RDKit fingerprints\")\n",
    "\n",
    "# RDKit fingerprints, length 1024 bits\n",
    "def RDKit_fingerprint(mol):\n",
    "    fp = np.zeros((1,))\n",
    "    ConvertToNumpyArray(RDKFingerprint(mol, 2, fpSize = 1024), fp)\n",
    "    return fp\n",
    "\n",
    "sol_data['fp_RDKit'] = sol_data['ROMol'].apply(RDKit_fingerprint)\n",
    "\n",
    "print(\"Converting Topological torsion fingerprints\")\n",
    "\n",
    "# Topological torsion (1987), length 1024 bits\n",
    "def Torsion_fingerprint(mol):\n",
    "    fp = np.zeros((1,))\n",
    "    ConvertToNumpyArray(GetHashedTopologicalTorsionFingerprintAsBitVect(mol, nBits = 1024), fp)\n",
    "    return fp\n",
    "\n",
    "sol_data['fp_Torsion'] = sol_data['ROMol'].apply(RDKit_fingerprint)\n",
    "\n",
    "print(\"Converting Extended reduced graph approach fingerprints\")\n",
    "\n",
    "# ErG (Extended reduced graph approach) fingerprints (2006)\n",
    "# Create by researchers in Eli Lilly \n",
    "# http://pubs.acs.org/doi/abs/10.1021/ci050457y\n",
    "def ErG_fingerprint(mol):\n",
    "    return GetErGFingerprint(mol)\n",
    "\n",
    "sol_data['fp_ErG'] = sol_data['ROMol'].apply(ErG_fingerprint)\n",
    "\n",
    "print (\"Converting Avalon bit based fingerprints\")\n",
    "\n",
    "# Avalon bit based (2006), length 1024 bits\n",
    "def Avalon_fingerprint(mol):\n",
    "    fp = np.zeros((1,))\n",
    "    ConvertToNumpyArray(GetAvalonFP(mol, nBits = 1024), fp)\n",
    "    return fp\n",
    "\n",
    "sol_data['fp_Avalon'] = sol_data['ROMol'].apply(Avalon_fingerprint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating fp_Estate fingerprints\n",
      "Generating fp_Morgan fingerprints\n",
      "Generating  fp_RDKit fingerprints\n",
      "Generating fp_Torsion fingerprints\n",
      "Generating    fp_ErG fingerprints\n",
      "Generating fp_Avalon fingerprints\n",
      "----------------------------------\n",
      "   name          CV avg(|error|)\n",
      "----------------------------------\n",
      " fp_Estate            0.675 \n",
      " fp_Avalon            0.765 \n",
      "  fp_RDKit            0.795 \n",
      "fp_Torsion            0.795 \n",
      " fp_Morgan            0.859 \n",
      "    fp_ErG            1.280 \n",
      "----------------------------------\n",
      "Generating fp_Estate fingerprints\n",
      "Generating fp_Morgan fingerprints\n",
      "Generating  fp_RDKit fingerprints\n",
      "Generating fp_Torsion fingerprints\n",
      "Generating    fp_ErG fingerprints\n",
      "Generating fp_Avalon fingerprints\n",
      "----------------------------------\n",
      "   name          CV avg(|error|)\n",
      "----------------------------------\n",
      " fp_Estate            0.673 \n",
      "    fp_ErG            1.494 \n",
      " fp_Morgan            3.039 \n",
      "  fp_RDKit            3.363 \n",
      "fp_Torsion            3.363 \n",
      " fp_Avalon            3.781 \n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "StS = StandardScaler()\n",
    "\n",
    "fps = ['fp_Estate', 'fp_Morgan', 'fp_RDKit', 'fp_Torsion', 'fp_ErG', 'fp_Avalon']\n",
    "\n",
    "def get_model_cv(model, x, y, cv=20):\n",
    "    scores = cross_validation.cross_val_score(model, x, y, cv=cv, n_jobs=-1, \n",
    "                                              scoring='neg_mean_absolute_error')\n",
    "    return -1 * scores.mean()\n",
    "\n",
    "def try_fps(fps, model, y, verbose = True):\n",
    "\n",
    "    fps_score = {}\n",
    "\n",
    "    for fp in fps:\n",
    "        x = np.array(list(sol_data[fp]))\n",
    "        #X = np.array(list(sol_data[fp]))\n",
    "        #x = StS.fit_transform(X)\n",
    "        if verbose: print(\"Generating %9s fingerprints\" % (fp))\n",
    "        fps_score[fp] = get_model_cv(model, x, y)\n",
    "\n",
    "    fps_sorted = sorted(fps_score, key=fps_score.__getitem__, reverse=False)\n",
    "\n",
    "    #print(\"\\n Using Linear Regression Model: \", model)\n",
    "    print(\"----------------------------------\")\n",
    "    print(\"   name          CV avg(|error|)\")\n",
    "    print(\"----------------------------------\")\n",
    "    for i in range(len(fps_sorted)):\n",
    "        name = fps_sorted[i]\n",
    "        print(\"%10s            %5.3f \" % (name, fps_score[name]))\n",
    "    print(\"----------------------------------\")\n",
    "\n",
    "# Tikhonov estimation\n",
    "try_fps(fps, BayesianRidge(n_iter=300, tol=0.001, alpha_1=1e-03, alpha_2=1e-03, lambda_1=1e-03, lambda_2=1e-03), y, verbose=True)\n",
    "try_fps(fps, Ridge(alpha=1e-3), y, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(list(sol_data['fp_Estate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFmodel = GridSearchCV(RandomForestRegressor(), cv=20,\n",
    "                       param_grid={\"n_estimators\": np.linspace(50, 150, 25).astype('int')}, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "\n",
    "RFmodel = RFmodel.fit(X, y)\n",
    "Best_RandomForestRegressor = RFmodel.best_estimator_\n",
    "\n",
    "print(\"Best Random Forest model\")\n",
    "print(RFmodel.best_params_)\n",
    "print(-1*RFmodel.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPmodel = GridSearchCV(GaussianProcessRegressor(normalize_y=True), cv=20,\n",
    "                       param_grid={\"alpha\": np.logspace(-15, -10, 30),}, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "\n",
    "GPmodel = GPmodel.fit(X, y)\n",
    "Best_GaussianProcessRegressor = GPmodel.best_estimator_\n",
    "\n",
    "print(\"Best Gaussian Process model\")\n",
    "print(GPmodel.best_params_)\n",
    "print(-1*GPmodel.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KRmodel = GridSearchCV(KernelRidge(), cv=10,\n",
    "                       param_grid={\"alpha\": np.logspace(-10, -5, 10),\n",
    "                       \"gamma\": np.logspace(-12, -9, 10), \"kernel\" : ['laplacian', 'rbf']}, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "\n",
    "KRmodel = KRmodel.fit(X, y)\n",
    "Best_KernelRidge = KRmodel.best_estimator_\n",
    "\n",
    "print(\"Best Kernel Ridge model\")\n",
    "print(KRmodel.best_params_)\n",
    "print('Best score for Kernel Ridge model: '-1*KRmodel.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_grid = {'alpha': np.logspace(1e-11,1e-1,8)}\n",
    "\n",
    "ml_models = {\n",
    "            'Linear Regression': LinearRegression(),\n",
    "            'Kernel Ridge Regression': Best_KernelRidge,\n",
    "            'Guassian Process Regressor': Best_GaussianProcessRegressor,\n",
    "            'Support Vector Regression': SVR(),\n",
    "            'KNeighborsRegressor': KNeighborsRegressor(),\n",
    "            'Neural Network': MLPRegressor(alpha=100,max_iter=8000, hidden_layer_sizes=[8,6], early_stopping=False),\n",
    "            'Gradient Boosted Trees': GradientBoostingRegressor(n_estimators=100),\n",
    "            'Random forest': Best_RandomForestRegressor\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(y_pred_train, y_pred_test, y_train, y_test, title='', figsize=(6,4), fontsize=16):    \n",
    "    plt.clf()\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.scatter(y_train,y_pred_train, label = 'Train', c='blue')\n",
    "    plt.title(title,fontsize=fontsize+2)\n",
    "    plt.xlabel('Experimental Solubility (mol/L)', fontsize=fontsize)\n",
    "    plt.ylabel('Predicted Solubility (mol/L)', fontsize=fontsize)\n",
    "    plt.scatter(y_test,y_pred_test,c='lightgreen', label='Test', alpha = 0.8)\n",
    "    plt.legend(loc=4)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_scores = {}\n",
    "percent_errors = {}\n",
    "\n",
    "for (name, model) in ml_models.items():\n",
    "    #print(\"running %s\" % name)\n",
    "    scores = cross_validation.cross_val_score(model, X, y, cv=20, n_jobs=-1, scoring='neg_mean_absolute_error')\n",
    "    scores = -1*scores\n",
    "    mean_score = scores.mean()\n",
    "    mean_scores[name] = mean_score\n",
    "\n",
    "    X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "            \n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test  = model.predict(X_test)\n",
    "\n",
    "    percent_error = np.mean( 100*np.abs(y_test -y_pred_test)/np.abs(y_pred_test))\n",
    "\n",
    "    percent_errors[name] = percent_error\n",
    "\n",
    "    fulltitle = name+'\\n mean % error: '+str(percent_error)\n",
    "\n",
    "    # Call ploting function\n",
    "    #plot_results(y_pred_train, y_pred_test, y_train, y_test, title=fulltitle, figsize = (8,6))\n",
    "\n",
    "sorted_names = sorted(percent_errors, key=mean_scores.__getitem__, reverse=False)\n",
    "\n",
    "print(\"----------------------------------\")\n",
    "print(\"           ML model     &      % test err   & .    abs error in CV\")\n",
    "print(\"----------------------------------\")\n",
    "for i in range(len(sorted_names)):\n",
    "    name = sorted_names[i]\n",
    "    print(\"%30s & %5.3f & %5.3f \" % (name, percent_errors[name], mean_scores[name]))\n",
    "    \n",
    "print(\"----------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
